{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(813, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-bd49e55bd241>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  vocab = pd.read_csv('brown_vocab_100.txt' , header =None , sep='delimiter')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab = pd.read_csv('brown_vocab_100.txt' , header =None , sep='delimiter')\n",
    "print(vocab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modernizing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0          all\n",
       "1  modernizing"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_dict = {}\n",
    "vocab = vocab[0]\n",
    "\n",
    "# for ind, word in enumerate(vocab): \n",
    "#     word_index_dict[word] = ind\n",
    "\n",
    "##############################################################\n",
    "\n",
    "with open(\"brown_vocab_100.txt\") as f:\n",
    "    vocab = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "\n",
    "for ind, word in enumerate(vocab): \n",
    "    word_index_dict[word] = ind\n",
    "    \n",
    "    \n",
    "def save_dict_to_file(dic):\n",
    "    f = open('word_to_index_100.txt','w')\n",
    "    f.write(str(dic))\n",
    "    f.close()\n",
    "\n",
    "def load_dict_from_file():\n",
    "    f = open('word_to_index_100.txt','r')\n",
    "    data=f.read()\n",
    "    f.close()\n",
    "    return eval(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_file(word_index_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dict_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "812\n",
      "813\n"
     ]
    }
   ],
   "source": [
    "print(word_index_dict['all'])\n",
    "print(word_index_dict['resolution'])\n",
    "print(len(word_index_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 2 : \n",
    "# brown = pd.read_csv('brown_100.txt' , header =None , sep='delimiter')\n",
    "# brown.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataframe\n",
    "# a2 = np.zeros(813, dtype = \"int\")\n",
    "# for sent in brown[0]:\n",
    "#     text1 = re.sub('<s>|</s>', ' ', sent)\n",
    "#     text2 = text1.lower().strip().split()\n",
    "#     for word in text2:\n",
    "#         if word in word_index_dict:\n",
    "#             a2[word_index_dict[word]] = a2[word_index_dict[word]] +1\n",
    "            \n",
    "# a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 2) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"brown_100.txt\") as f:\n",
    "    brown = [line.rstrip('\\n') for line in f]\n",
    "#     brown = f.readline()\n",
    "# brown = brown[0]\n",
    "# brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place . </s> \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file \n",
    "\n",
    "def load_dict_from_file():\n",
    "    f = open('word_to_index_100.txt','r')\n",
    "    data=f.read()\n",
    "    f.close()\n",
    "    return eval(data)\n",
    "\n",
    "word_index_dict = load_dict_from_file()\n",
    "# word_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_word(word_input, word_index_dict_input):\n",
    "    count_vector = np.zeros(813, dtype = \"int\")\n",
    "    for sent in word_input:\n",
    "        text1 = re.sub('<s>|</s>', ' ', sent)\n",
    "        text2 = text1.lower().strip().split()\n",
    "        for word in text2:\n",
    "            if word in word_index_dict_input:\n",
    "                count_vector[word_index_dict_input[word]] = count_vector[word_index_dict_input[word]] +1\n",
    "                \n",
    "    return count_vector\n",
    "\n",
    "# a2 = np.zeros(813, dtype = \"int\")\n",
    "# for sent in brown:\n",
    "#     text1 = re.sub('<s>|</s>', ' ', sent)\n",
    "#     text2 = text1.lower().strip().split()\n",
    "#     for word in text2:\n",
    "#         if word in word_index_dict:\n",
    "#             a2[word_index_dict[word]] = a2[word_index_dict[word]] +1\n",
    "            \n",
    "# # a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = count_word(brown, word_index_dict)\n",
    "# arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = (arr2 / np.sum(arr2))\n",
    "# probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0004409171075837742, 0.003968253968253968)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0] , probs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite your new probs vector to a file called unigram_probs.txt and verify that the first probability in it\\n(the probability of ‘all’) is 0.00040519 and that the last probability (probability of ‘resolution’) is 0.00364668.\\n(Note that our model trained on this small corpus has estimated that ‘resolution’ is about 10 times as frequent as \\n‘all’! Models trained on very small corpora are very noisy.)\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write your new probs vector to a file called unigram_probs.txt and verify that the first probability in it\n",
    "(the probability of ‘all’) is 0.00040519 and that the last probability (probability of ‘resolution’) is 0.00364668.\n",
    "(Note that our model trained on this small corpus has estimated that ‘resolution’ is about 10 times as frequent as \n",
    "‘all’! Models trained on very small corpora are very noisy.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math as m\n",
    "m.ceil(6.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros(813 , dtype = \"int\")\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(dic, value):\n",
    "    for k, v in dic.items():\n",
    "        if k == value:\n",
    "            return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_value(d, \"rob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GENERATE(word_index_dict, probs, model_type, max_words, start_word):\n",
    "    returnSTR = \"\"\n",
    "    index_word_dict = {v: k for k, v in word_index_dict.items()}\n",
    "    num_words = 0\n",
    "\n",
    "    #been passed a list of probabilities\n",
    "    if model_type == \"unigram\":\n",
    "\n",
    "        #using https://stackoverflow.com/questions/483666/python-reverse-invert-a-mapping\n",
    "        while(True):\n",
    "            wordIndex = np.random.choice(len(word_index_dict), 1, p=list(probs))\n",
    "            word = index_word_dict[wordIndex[0]]\n",
    "            returnSTR += word + \" \"\n",
    "            num_words +=1\n",
    "            if word == \"</s>\" or num_words == max_words:\n",
    "                break\n",
    "\n",
    "        return returnSTR\n",
    "\n",
    "    #been passed a matrix of probabilities, where each row is the previous word. \n",
    "    if model_type == \"bigram\":\n",
    "        returnSTR = start_word + \" \"\n",
    "        prevWord = start_word\n",
    "        while(True):\n",
    "            wordIndex = np.random.choice(len(word_index_dict), 1, p=list(probs[word_index_dict[prevWord]]))\n",
    "            word = index_word_dict[wordIndex[0]]\n",
    "            returnSTR += word + \" \"\n",
    "            num_words +=1\n",
    "            prevWord = word\n",
    "            if word == \"</s>\" or num_words == max_words:\n",
    "                break\n",
    "\n",
    "        return returnSTR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'enabling the '"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = \"unigram\"\n",
    "\n",
    "# model_type = \"bigram\"\n",
    "\n",
    "max_words = 2\n",
    "\n",
    "start_word = \"all\"\n",
    "\n",
    "GENERATE(word_index_dict, probs, model_type, max_words, start_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = {v : k for k,v in word_index_dict.items()}\n",
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = word_index_dict\n",
    "t[\"rob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004409171075837742"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevWord = \"rob\"\n",
    "\n",
    "# list(probs[word_index_dict[prevWord]])\n",
    "\n",
    "probs[word_index_dict[prevWord]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# probs_2 = normalize(probs, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 3, 1, 5])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.seed(3)\n",
    "np.random.choice(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(5, 3, p = [0.2, 0.1, 0.3, 0.4, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = np.zeros(813, dtype = \"int\")\n",
    "    for sent in word_input:\n",
    "        text1 = re.sub('<s>|</s>', ' ', sent)\n",
    "        text2 = text1.lower().strip().split()\n",
    "        for word in text2:\n",
    "            if word in word_index_dict_input:\n",
    "                count_vector[word_index_dict_input[word]] = count_vector[word_index_dict_input[word]] +1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prev = '<s>'\n",
    "dic3 = {}\n",
    "total_count = 0\n",
    "for sent in brown:\n",
    "    text2 = sent.lower().strip().split()\n",
    "    for word in text2:\n",
    "        #print(prev,word)\n",
    "        if not (prev,word) in dic3:\n",
    "            dic3[(prev,word)]=1\n",
    "            prev = word\n",
    "        else:\n",
    "            dic3[(prev,word)]+=1\n",
    "            prev = word\n",
    "            total_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017035775127768314"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic3[('all', 'the')] / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic4 ={}\n",
    "a=0\n",
    "for i,v in dic3.items():\n",
    "    dic4[a]= i\n",
    "    a=a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1881"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix = np.zeros([len(dic4),2])\n",
    "count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1881):\n",
    "    count_matrix[i][0]= int(i)\n",
    "    count_matrix[i][1]= dic3[dic4[i]] / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.70357751e-03],\n",
       "       [1.00000000e+00, 4.59965928e-02],\n",
       "       [2.00000000e+00, 1.02214651e-02],\n",
       "       ...,\n",
       "       [1.87800000e+03, 1.70357751e-03],\n",
       "       [1.87900000e+03, 1.70357751e-03],\n",
       "       [1.88000000e+03, 1.70357751e-03]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0, 0.013628620102214651)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix[0][0], count_matrix[6][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "probs = normalize(count_matrix, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00],\n",
       "       [9.56026059e-01, 4.39739414e-02],\n",
       "       [9.94915254e-01, 5.08474576e-03],\n",
       "       ...,\n",
       "       [9.99999093e-01, 9.07122453e-07],\n",
       "       [9.99999093e-01, 9.06639685e-07],\n",
       "       [9.99999094e-01, 9.06157430e-07]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
