{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='red' > Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iteration_utilities import duplicates\n",
    "\n",
    "# import gym # why use gym ?????\n",
    "\n",
    "from scipy import stats as s\n",
    "from random import randint\n",
    "from re import search\n",
    "from pathlib import Path\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import csv\n",
    "\n",
    "# import pprint\n",
    "from pprint import pprint \n",
    "import re, pprint, random, requests, glob\n",
    "\n",
    "\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "#ProfileReport(df) # get all details like : min, max, correlation, else\n",
    "\n",
    "# %matplotlib notebook vs %matplotlib inline #vvi : %matplotlib notebook\n",
    "\n",
    "\n",
    "from scipy.stats import mstats\n",
    "\n",
    "# df=pd.read_csv(\"CarPrice_Assignment.csv\",encoding = \"ISO-8859-1\",low_memory=False)\n",
    "\n",
    " #************ titanic_df.profile_report() #VVI \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "import sys\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from timeit import timeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='green' > Common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "from collections import Counter , defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "from pandas import Series as s , DataFrame as df\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from matplotlib import pyplot as plt, rcParams as rc\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "rc[\"figure.figsize\"] = 10,6\n",
    "\n",
    "\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='red' > Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor , XGBRFRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor # why?\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='orange' > Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "#Modle Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, recall_score, precision_score, explained_variance_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='blue' > HighLevel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from imblearn.combine import SMOTETomek # over sampling method 1\n",
    "\n",
    "## RandomOverSampler to handle imbalanced data\n",
    "from imblearn.over_sampling import RandomOverSampler # over sampling method 2\n",
    "\n",
    "\n",
    "#Shuffle the dataframe\n",
    "# from sklearn.utils import shuffle # df1 = shuffle(df).reset_index(drop = True)\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.api as sm \n",
    "\n",
    "\n",
    "from pickle import dump, load\n",
    "from joblib import dump, load\n",
    "\n",
    "import datetime\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection  import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from iteration_utilities import duplicates, unique_everseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='red' > Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color ='yellow' > NLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint, random\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Set\n",
    "\n",
    "pd.options.display.max_columns = 250\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"check time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    ">>> L = [1, 2, 45, 55, 5, 4, 4, 4, 4, 4, 4, 5456, 56, 6, 7, 67] \n",
    ">>> statistics.mode(L)\n",
    "\n",
    "l1 = [1,2,3,2,3,2,3]\n",
    "statistics.mode(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on Key = 0, based on value = 1 and based on Ascending = False or Descending = True\n",
    "#Default based on value and ascending\n",
    "\n",
    "def reverse_dict(dict_val , key_value = 1, ascending_descending = False):\n",
    "    \n",
    "    val = sorted(dict_val.items(), key = lambda x: x[key_value] , reverse = ascending_descending)\n",
    "    \n",
    "    return dict(val)\n",
    "\n",
    "def no_of_item_dict(dict_val , no_of_item):\n",
    "    dict_len = len(dict_val)\n",
    "    \n",
    "    if(dict_len != 0 and dict_len != 0 and  no_of_item <= dict_len):\n",
    "        for ind, val in enumerate(dict_val):\n",
    "            if(ind < no_of_item):\n",
    "                print(val[0] , \" \", val[1])                \n",
    "    else:\n",
    "        print(\"Please enter the valid input\")\n",
    "\n",
    "\n",
    "marks = {\"Raka\" : 99, \"ananya\" : 90 ,'John':85, 'Alex':80, 'Richard': 87, \"rakesh\" : 97 , \"Trishala\" : 92}\n",
    "dic_sorted = reverse_dict(marks, 0, False)\n",
    "\n",
    "print(dic_sorted)\n",
    "\n",
    "no_of_item_dict(dic_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra VVI Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list() or list(df.columns) or list(df.iloc[:,0:].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir('.') if os.path.isfile(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE  : %f\\nMSE  : %f\\nMSLE : %f\\nRMSE : %F\"%(MAE, MSE, MSLE, RMSE)) # %f or %F\n",
    "\n",
    "df['Var1'].fillna(df['Var1'].mean(), inplace=True)\n",
    "df['Var1'] = np.log(df['Var1'])\n",
    "\n",
    "combine = train.append(test)\n",
    "\n",
    "df.Type_of_Cab.fillna(method='bfill',inplace=True)\n",
    "\n",
    "\n",
    "features = np.setdiff1d(train.columns, ['Trip_ID', 'Surge_Pricing_Type']) \n",
    "# means: features do not hv 'Trip_ID', 'Surge_Pricing_Type' columns\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Sat May 16 09:22:18 2020\n",
    "\n",
    "@author: I354298\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0,100,size=(10, 5)), columns=list('ABCDE'))\n",
    "df2[\"target\"] = [2,1,1,2,1,2,1,1,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Checking Distribution of data\n",
    "\n",
    "#Checking distribution of data via pandas visualization\n",
    "train[col_name].hist(figsize=(20,20),color='g',alpha = 0.7)\n",
    "#plt.savefig('distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(compare,predicted)\n",
    "\n",
    "#Get all int columns\n",
    "high_value_cust.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "#\n",
    "var1_median = train.Var1.dropna().median()\n",
    "df['Var1'] = df['Var1'].fillna(var1_median)\n",
    "\n",
    "\n",
    "\n",
    "# 0 - not churn, 1 - churn\n",
    "churn_filtered['churn'] = churn_filtered.apply(lambda row: 1 if (row.total_calls_mou_9 == 0 and row.total_internet_mb_9 == 0) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select_dtypes(exclude=['object'])\n",
    "\n",
    "\n",
    "\n",
    "telecom_df.info(verbose = True) or telecom_df.info(verbose = 1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
